{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# åœºæ™¯å››ï¼šè‡ªç„¶è¯­è¨€äº¤æµçš„æœç´¢å¼•æ“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pulling manifest\n",
      "pulling 8359bebea988... 100% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| (7.4/7.4 GB, 75 TB/s)        \n",
      "pulling 65c6ec5c6ff0... 100% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| (45/45 B, 2.4 MB/s)        \n",
      "pulling dd36891f03a0... 100% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| (31/31 B, 1.3 MB/s)        \n",
      "pulling f94f529485e6... 100% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| (382/382 B, 19 MB/s)        \n",
      "verifying sha256 digest\n",
      "writing manifest\n",
      "removing any unused layers\n",
      "success\n"
     ]
    }
   ],
   "source": [
    "!ollama pull llama2-chinese:13b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain langchainhub langchain-experimental\n",
    "%pip install python-dotenv openai duckduckgo-search numexpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find out what the temperatures are in Beijing and Shanghai today.\n",
      "Action: duckduckgo_search\n",
      "Action Input: \"Beijing temperature today\"\u001b[0m\u001b[36;1m\u001b[1;3mWeather report for Beijing. Overnight into Tuesday it is mostly cloudy, but most clouds give way early in the day. For the afternoon clear skies prevail. It is a sunny day. Temperatures as high as 72 Â°F are foreseen. During the night and in the first hours of the day light air is noticeable (1 to 4 mph). Beijing 7 day weather forecast including weather warnings, temperature, rain, wind, visibility, humidity and UV 6:23 AM5:36 PM. Morning temperature of 50 degrees, afternoon 70Â°, evening 50Â° and night 45Â°. Clear, evening mostly clear. The hourly local weather forecast shows hour by hour weather conditions like temperature, feels like temperature, humidity, amount of precipitation and chance of precipitation, wind and gusts for Beijing. Beijing. Beijing Weather Forecast. Providing a local hourly Beijing weather forecast of rain, sun, wind, humidity and temperature. The Long-range 12 day forecast also includes detail for Beijing weather today. Live weather reports from Beijing weather stations and weather warnings that include risk of thunder, high UV index and forecast gales. Plenty of sunshine. High 73F. Winds S at 10 to 15 mph. Tonight Tue 10/31 Low 54 Â°F. 24% Precip. / 0.00in. Partly to mostly cloudy. Low 54F. Winds light and variable. Tomorrow Wed 11/01 High 74 ...\u001b[0m\u001b[32;1m\u001b[1;3m I need to find out what the temperatures are in Shanghai today.\n",
      "Action: duckduckgo_search\n",
      "Action Input: \"Shanghai temperature today\"\u001b[0m\u001b[36;1m\u001b[1;3m26Â° 19Â° Fri 3 Nov 28Â° 20Â° Sat 4 Nov 25Â° 18Â° Sun 5 Nov 22Â° 12Â° Mon 6 Nov Today Tuesday Wednesday Thursday Friday Saturday Sunday Monday Updated: 11:37 (UTC) on Mon 30 Oct 2023 Show full forecast... Today 84 Â°F 65 Â°F 8 mph - 9 h 1 hour view The weather forecast has very high predictability. Compare different forecasts with MultiModel. Weather report for Shanghai During the night and in the first hours of the day clear skies prevail, but for this afternoon a few clouds are expected. It is a sunny day. 77Â° | 61Â° 60 Â°F like 60Â° Fair N 2 Today's temperature is forecast to be NEARLY THE SAME as yesterday. Radar Satellite WunderMap Today Sat 10/28 High 77 Â°F 2% Precip. / 0.00 in Partly cloudy.... China Shanghai Shanghai Weather Forecast. Providing a local hourly Shanghai weather forecast of rain, sun, wind, humidity and temperature. The Long-range 12 day forecast also includes detail for Shanghai weather today. Thursday 9 Nov. 19Â° / 18Â°. 3.5 mm. 4 m/s. Open hourly forecast. Updated 21:30. How often is the weather forecast updated? Forecast as PDF Forecast as SVG. Weather forecast for Shanghai for the next 9 days.\u001b[0m\u001b[32;1m\u001b[1;3m I now know the temperatures for both cities, and can calculate the difference.\n",
      "Action: Calculator\n",
      "Action Input: 72 - 77\u001b[0m\u001b[33;1m\u001b[1;3mAnswer: -5\u001b[0m\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: ä»Šå¤©ä¸Šæµ·å’ŒåŒ—äº¬çš„æ°”æ¸©å·®äº”åº¦ã€‚\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'ä»Šå¤©ä¸Šæµ·å’ŒåŒ—äº¬çš„æ°”æ¸©å·®å‡ åº¦ï¼Ÿ', 'output': 'ä»Šå¤©ä¸Šæµ·å’ŒåŒ—äº¬çš„æ°”æ¸©å·®äº”åº¦ã€‚'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import hub\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.agents import load_tools \n",
    "from langchain.agents import AgentExecutor\n",
    "from langchain.agents.output_parsers import ReActSingleInputOutputParser\n",
    "from langchain.agents.format_scratchpad import format_log_to_str\n",
    "from langchain.tools.render import render_text_description\n",
    "\n",
    "# é€šè¿‡ python-dotenv åŠ è½½ç¯å¢ƒå˜é‡\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# å‡†å¤‡å¤§è¯­è¨€æ¨¡å‹ï¼šè¿™é‡Œéœ€è¦ OpenAIï¼Œå¯ä»¥æ–¹ä¾¿åœ°æŒ‰éœ€åœæ­¢æ¨ç†\n",
    "llm = OpenAI()\n",
    "llm_with_stop = llm.bind(stop=[\"\\nObservation\"])\n",
    "\n",
    "# å‡†å¤‡æˆ‘ä»¬çš„å·¥å…·ï¼šè¿™é‡Œç”¨åˆ° DuckDuckGo æœç´¢å¼•æ“ï¼Œå’Œä¸€ä¸ªåŸºäº LLM çš„è®¡ç®—å™¨\n",
    "tools = load_tools([\"ddg-search\", \"llm-math\"], llm=llm)\n",
    "\n",
    "# å‡†å¤‡æ ¸å¿ƒæç¤ºè¯ï¼šè¿™é‡Œä» LangChain Hub åŠ è½½äº† ReAct æ¨¡å¼çš„æç¤ºè¯ï¼Œå¹¶å¡«å……å·¥å…·çš„æ–‡æœ¬æè¿°\n",
    "prompt = hub.pull(\"hwchase17/react\")\n",
    "prompt = prompt.partial(\n",
    "    tools=render_text_description(tools),\n",
    "    tool_names=\", \".join([t.name for t in tools]),\n",
    ")\n",
    "\n",
    "# æ„å»º Agent çš„å·¥ä½œé“¾ï¼šè¿™é‡Œæœ€é‡è¦çš„æ˜¯æŠŠä¸­é—´æ­¥éª¤çš„ç»“æ„è¦ä¿å­˜åˆ°æç¤ºè¯çš„ agent_scratchpad ä¸­\n",
    "agent = (\n",
    "    {\n",
    "        \"input\": lambda x: x[\"input\"],\n",
    "        \"agent_scratchpad\": lambda x: format_log_to_str(x[\"intermediate_steps\"]),\n",
    "    }\n",
    "    | prompt\n",
    "    | llm_with_stop\n",
    "    | ReActSingleInputOutputParser()\n",
    ")\n",
    "\n",
    "# æ„å»º Agent æ‰§è¡Œå™¨ï¼šæ‰§è¡Œå™¨è´Ÿè´£æ‰§è¡Œ Agent å·¥ä½œé“¾ï¼Œç›´è‡³å¾—åˆ°æœ€ç»ˆç­”æ¡ˆï¼ˆçš„æ ‡è¯†ï¼‰å¹¶è¾“å‡ºå›ç­”\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "agent_executor.invoke({\"input\": \"ä»Šå¤©ä¸Šæµ·å’ŒåŒ—äº¬çš„æ°”æ¸©å·®å‡ åº¦ï¼Ÿ\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¯·å…ˆè¿è¡Œæœ¬ä»£ç å—ï¼Œå†æ‰§è¡Œä¸‹ä¸€ä¸ªç¤ºä¾‹\n",
    "%pip install playwright\n",
    "!playwright install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mAction:\n",
      "```\n",
      "{\n",
      "  \"action\": \"navigate_browser\",\n",
      "  \"action_input\": {\n",
      "    \"url\": \"https://blog.langchain.dev\"\n",
      "  }\n",
      "}\n",
      "```\u001b[0m\u001b[33;1m\u001b[1;3mNavigating to https://blog.langchain.dev returned status code 200\u001b[0m\u001b[32;1m\u001b[1;3mObservation: Navigating to the webpage \"https://blog.langchain.dev\" returned a status code of 200, indicating that the webpage was successfully loaded.\n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"extract_text\",\n",
      "  \"action_input\": {}\n",
      "}\n",
      "```\u001b[0m\u001b[31;1m\u001b[1;3mLangChain Blog Skip to content LangChain Blog Home By LangChain Release Notes GitHub Docs Case Studies Sign in Subscribe Query Construction Key Links\n",
      "\n",
      " * Text-to-metadata: Updated self-query docs and template\n",
      " * Text-to-SQL+semantic: Cookbook and template\n",
      "\n",
      "There's great interest in seamlessly connecting natural language with diverse types of 7 min read Featured Building LLM-Powered Web Apps with Client-Side Technology By LangChain 5 min read Fine-tuning ChatGPT: Surpassing GPT-4 Summarization Performanceâ€“A 63% Cost Reduction and 11x Speed Enhancement using Synthetic Data and LangSmith 5 min read Building (and Breaking) WebLangChain By LangChain 12 min read Building Chat LangChain 7 min read Morningstar Intelligence Engine puts personalized investment insights at analystâ€™s fingertips Challenge\n",
      "\n",
      "Financial services is one of the most data-driven industries and financial professionals are always hungry for more data and better tools to drive value Case Studies 2 min read Parallel Function Calling for Structured Data Extraction Important Links:\n",
      "\n",
      " * Cookbook for extraction using parallel function calling\n",
      "\n",
      "One of the biggest use cases for language models that we see is in extraction. This 4 min read â™ ï¸ SPADE: Automatically Digging up Evals based on Prompt Refinements Written by Shreya Shankar (UC Berkeley) in collaboration with Haotian Li (HKUST), Will Fu-Hinthorn (LangChain), Harrison Chase (LangChain), J.D. Zamfirescu-Pereira (UC Berkeley), Yiming Lin 6 min read Implementing advanced RAG strategies with Neo4j Editor's note: We're excited to share this blogpost as it covers several of the advanced retrieval strategies we introduced in the past month, specifically a 7 min read [Week of 10/30] LangChain Release Notes Announcing LangChain Templates\n",
      "\n",
      "A collection of easily deployable reference architectures for a wide variety of tasks so you can get going fast.\n",
      "\n",
      " * Learn more about Release Notes 3 min read Embeddings Drive the Quality of RAG: Voyage AI in Chat LangChain Editor's Note: This post was written by the Voyage AI team.\n",
      "\n",
      "This post demonstrates that the choice of embedding models significantly impacts the overall quality 6 min read LangChain Templates Today we're excited to announce the release of LangChain Templates. LangChain Templates offers a collection of easily deployable reference architectures that anyone can use. We've 6 min read Announcing Data Annotation Queues ğŸ’¡Data Annotation Queues are a new feature in LangSmith, our developer platform aimed at helping bring LLM applications from prototype to production. Sign up for 4 min read Query Transformations Naive RAG typically splits documents into chunks, embeds them, and retrieves chunks with high semantic similarity to a user question. But, this present a few 4 min read LangChain's First Birthday Itâ€™s LangChainâ€™s first birthday! Itâ€™s been a really exciting year!\n",
      "\n",
      "We worked with thousands of developers building LLM applications and tooling. We By LangChain 15 min read Beyond Text: Making GenAI Applications Accessible to All Editor's Note: This post was written by Andres Torres and Dylan Brock from Norwegian Cruise Line. Building UI/UX for AI applications is hard and 8 min read Robocorpâ€™s code generation assistant makes building Python automation easy for developers Challenge\n",
      "\n",
      "Robocorp was founded in 2019 out of frustration that the promise of developers being able to automate monotonous work hadnâ€™t been realized. Right Case Studies 2 min read Page 1 of 12 Load More Something went wrong with loading more posts Sign up Â© LangChain Blog 2023 - Powered by Ghost\u001b[0m\u001b[32;1m\u001b[1;3mThought: The webpage \"https://blog.langchain.dev\" contains various content, including blog posts, release notes, case studies, and important links. Some of the recent blog posts include \"Building LLM-Powered Web Apps with Client-Side Technology,\" \"Fine-tuning ChatGPT: Surpassing GPT-4 Summarization Performanceâ€“A 63% Cost Reduction and 11x Speed Enhancement using Synthetic Data and LangSmith,\" and \"Building (and Breaking) WebLangChain.\" Additionally, there are case studies and important links related to language models and data extraction. \n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"The webpage contains various content, including blog posts, release notes, case studies, and important links related to language models and data extraction.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'è¯·è®¿é—®è¿™ä¸ªç½‘é¡µå¹¶æ€»ç»“ä¸€ä¸‹ä¸Šé¢çš„å†…å®¹ï¼šblog.langchain.dev',\n",
       " 'output': 'The webpage contains various content, including blog posts, release notes, case studies, and important links related to language models and data extraction.'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import hub\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.agents import AgentExecutor\n",
    "from langchain.agents.format_scratchpad import format_log_to_str\n",
    "from langchain.agents.output_parsers import JSONAgentOutputParser\n",
    "from langchain.agents.agent_toolkits import PlayWrightBrowserToolkit\n",
    "from langchain.tools.render import render_text_description_and_args\n",
    "from langchain.tools.playwright.utils import create_async_playwright_browser\n",
    "\n",
    "# é¿å… Jupter Notebook äº§ç”Ÿ EventLoop é—®é¢˜\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# é€šè¿‡ python-dotenv åŠ è½½ç¯å¢ƒå˜é‡\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# å‡†å¤‡å¤§è¯­è¨€æ¨¡å‹ï¼šè¿™é‡Œéœ€è¦ OpenAIï¼Œå¯ä»¥æ–¹ä¾¿åœ°æŒ‰éœ€åœæ­¢æ¨ç†\n",
    "llm = ChatOpenAI()\n",
    "llm_with_stop = llm.bind(stop=[\"\\nObservation\"])\n",
    "\n",
    "# å‡†å¤‡ Browser å·¥å…·é›†\n",
    "async_browser = create_async_playwright_browser()\n",
    "browser_toolkit = PlayWrightBrowserToolkit.from_browser(async_browser=async_browser)\n",
    "tools = browser_toolkit.get_tools()\n",
    "\n",
    "# å‡†å¤‡æ ¸å¿ƒæç¤ºè¯ï¼šè¿™é‡Œä» LangChain Hub åŠ è½½äº† ReAct å¤šå‚æ•°è¾“å…¥æ¨¡å¼çš„æç¤ºè¯ï¼Œå¹¶å¡«å……å·¥å…·çš„æ–‡æœ¬æè¿°\n",
    "prompt = hub.pull(\"hwchase17/react-multi-input-json\")\n",
    "prompt = prompt.partial(\n",
    "    tools=render_text_description_and_args(tools),\n",
    "    tool_names=\", \".join([t.name for t in tools]),\n",
    ")\n",
    "\n",
    "# æ„å»º Agent çš„å·¥ä½œé“¾ï¼šè¿™é‡Œæœ€é‡è¦çš„æ˜¯æŠŠä¸­é—´æ­¥éª¤çš„ç»“æ„è¦ä¿å­˜åˆ°æç¤ºè¯çš„ agent_scratchpad ä¸­\n",
    "agent = (\n",
    "    {\n",
    "        \"input\": lambda x: x[\"input\"],\n",
    "        \"agent_scratchpad\": lambda x: format_log_to_str(x[\"intermediate_steps\"]),\n",
    "    }\n",
    "    | prompt\n",
    "    | llm_with_stop\n",
    "    | JSONAgentOutputParser()\n",
    ")\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "# å› ä¸ºä½¿ç”¨äº†å¼‚æ­¥æµè§ˆå™¨é¡µé¢æŠ“å–å·¥å…·ï¼Œè¿™é‡Œå¯¹åº”åœ°ä½¿ç”¨å¼‚æ­¥çš„æ–¹å¼è¿›è¡Œ Agent æ‰§è¡Œ\n",
    "await agent_executor.ainvoke({\"input\": \"è¯·è®¿é—®è¿™ä¸ªç½‘é¡µå¹¶æ€»ç»“ä¸€ä¸‹ä¸Šé¢çš„å†…å®¹ï¼šblog.langchain.dev\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.10/site-packages/langchain/tools/shell/tool.py:31: UserWarning: The shell tool has no safeguards by default. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/home/codespace/.python/current/lib/python3.10/site-packages/langchain/tools/shell/tool.py:31: UserWarning: The shell tool has no safeguards by default. Use at your own risk.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bin\n",
      "games\n",
      "include\n",
      "lib\n",
      "lib32\n",
      "lib64\n",
      "libexec\n",
      "libx32\n",
      "local\n",
      "sbin\n",
      "share\n",
      "src\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in HumanApprovalCallbackHandler.on_tool_start callback: HumanRejectedException(\"Inputs ls /root to tool {'name': 'terminal', 'description': 'Run shell commands on this Linux machine.'} were rejected.\")\n"
     ]
    },
    {
     "ename": "HumanRejectedException",
     "evalue": "Inputs ls /root to tool {'name': 'terminal', 'description': 'Run shell commands on this Linux machine.'} were rejected.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHumanRejectedException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m/workspaces/langchain-in-action/use-cases/web-search.ipynb Cell 7\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell://codespaces%2Blaughing-guide-9qxrjv6qjqfp575/workspaces/langchain-in-action/use-cases/web-search.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m tool \u001b[39m=\u001b[39m ShellTool(callbacks\u001b[39m=\u001b[39m[HumanApprovalCallbackHandler()])\n\u001b[1;32m      <a href='vscode-notebook-cell://codespaces%2Blaughing-guide-9qxrjv6qjqfp575/workspaces/langchain-in-action/use-cases/web-search.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(tool\u001b[39m.\u001b[39mrun(\u001b[39m\"\u001b[39m\u001b[39mls /usr\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[0;32m----> <a href='vscode-notebook-cell://codespaces%2Blaughing-guide-9qxrjv6qjqfp575/workspaces/langchain-in-action/use-cases/web-search.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mprint\u001b[39m(tool\u001b[39m.\u001b[39;49mrun(\u001b[39m\"\u001b[39;49m\u001b[39mls /root\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/langchain/tools/base.py:327\u001b[0m, in \u001b[0;36mBaseTool.run\u001b[0;34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[39m# TODO: maybe also pass through run_manager is _run supports kwargs\u001b[39;00m\n\u001b[1;32m    326\u001b[0m new_arg_supported \u001b[39m=\u001b[39m signature(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run)\u001b[39m.\u001b[39mparameters\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mrun_manager\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 327\u001b[0m run_manager \u001b[39m=\u001b[39m callback_manager\u001b[39m.\u001b[39;49mon_tool_start(\n\u001b[1;32m    328\u001b[0m     {\u001b[39m\"\u001b[39;49m\u001b[39mname\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname, \u001b[39m\"\u001b[39;49m\u001b[39mdescription\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdescription},\n\u001b[1;32m    329\u001b[0m     tool_input \u001b[39mif\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(tool_input, \u001b[39mstr\u001b[39;49m) \u001b[39melse\u001b[39;49;00m \u001b[39mstr\u001b[39;49m(tool_input),\n\u001b[1;32m    330\u001b[0m     color\u001b[39m=\u001b[39;49mstart_color,\n\u001b[1;32m    331\u001b[0m     name\u001b[39m=\u001b[39;49mrun_name,\n\u001b[1;32m    332\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    333\u001b[0m )\n\u001b[1;32m    334\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    335\u001b[0m     tool_args, tool_kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_to_args_and_kwargs(parsed_input)\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/langchain/callbacks/manager.py:1389\u001b[0m, in \u001b[0;36mCallbackManager.on_tool_start\u001b[0;34m(self, serialized, input_str, run_id, parent_run_id, **kwargs)\u001b[0m\n\u001b[1;32m   1386\u001b[0m \u001b[39mif\u001b[39;00m run_id \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1387\u001b[0m     run_id \u001b[39m=\u001b[39m uuid\u001b[39m.\u001b[39muuid4()\n\u001b[0;32m-> 1389\u001b[0m handle_event(\n\u001b[1;32m   1390\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandlers,\n\u001b[1;32m   1391\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mon_tool_start\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   1392\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mignore_agent\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   1393\u001b[0m     serialized,\n\u001b[1;32m   1394\u001b[0m     input_str,\n\u001b[1;32m   1395\u001b[0m     run_id\u001b[39m=\u001b[39;49mrun_id,\n\u001b[1;32m   1396\u001b[0m     parent_run_id\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparent_run_id,\n\u001b[1;32m   1397\u001b[0m     tags\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtags,\n\u001b[1;32m   1398\u001b[0m     metadata\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmetadata,\n\u001b[1;32m   1399\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m   1400\u001b[0m )\n\u001b[1;32m   1402\u001b[0m \u001b[39mreturn\u001b[39;00m CallbackManagerForToolRun(\n\u001b[1;32m   1403\u001b[0m     run_id\u001b[39m=\u001b[39mrun_id,\n\u001b[1;32m   1404\u001b[0m     handlers\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandlers,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1410\u001b[0m     inheritable_metadata\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39minheritable_metadata,\n\u001b[1;32m   1411\u001b[0m )\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/langchain/callbacks/manager.py:447\u001b[0m, in \u001b[0;36mhandle_event\u001b[0;34m(handlers, event_name, ignore_condition_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    442\u001b[0m             logger\u001b[39m.\u001b[39mwarning(\n\u001b[1;32m    443\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mError in \u001b[39m\u001b[39m{\u001b[39;00mhandler\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mevent_name\u001b[39m}\u001b[39;00m\u001b[39m callback:\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    444\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mrepr\u001b[39m(e)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    445\u001b[0m             )\n\u001b[1;32m    446\u001b[0m             \u001b[39mif\u001b[39;00m handler\u001b[39m.\u001b[39mraise_error:\n\u001b[0;32m--> 447\u001b[0m                 \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    448\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    449\u001b[0m     \u001b[39mif\u001b[39;00m coros:\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/langchain/callbacks/manager.py:419\u001b[0m, in \u001b[0;36mhandle_event\u001b[0;34m(handlers, event_name, ignore_condition_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    416\u001b[0m     \u001b[39mif\u001b[39;00m ignore_condition_name \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mgetattr\u001b[39m(\n\u001b[1;32m    417\u001b[0m         handler, ignore_condition_name\n\u001b[1;32m    418\u001b[0m     ):\n\u001b[0;32m--> 419\u001b[0m         event \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39;49m(handler, event_name)(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    420\u001b[0m         \u001b[39mif\u001b[39;00m asyncio\u001b[39m.\u001b[39miscoroutine(event):\n\u001b[1;32m    421\u001b[0m             coros\u001b[39m.\u001b[39mappend(event)\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/langchain/callbacks/human.py:48\u001b[0m, in \u001b[0;36mHumanApprovalCallbackHandler.on_tool_start\u001b[0;34m(self, serialized, input_str, run_id, parent_run_id, **kwargs)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mon_tool_start\u001b[39m(\n\u001b[1;32m     39\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m     40\u001b[0m     serialized: Dict[\u001b[39mstr\u001b[39m, Any],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m     46\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m     47\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_check(serialized) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_approve(input_str):\n\u001b[0;32m---> 48\u001b[0m         \u001b[39mraise\u001b[39;00m HumanRejectedException(\n\u001b[1;32m     49\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInputs \u001b[39m\u001b[39m{\u001b[39;00minput_str\u001b[39m}\u001b[39;00m\u001b[39m to tool \u001b[39m\u001b[39m{\u001b[39;00mserialized\u001b[39m}\u001b[39;00m\u001b[39m were rejected.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     50\u001b[0m         )\n",
      "\u001b[0;31mHumanRejectedException\u001b[0m: Inputs ls /root to tool {'name': 'terminal', 'description': 'Run shell commands on this Linux machine.'} were rejected."
     ]
    }
   ],
   "source": [
    "from langchain.callbacks import HumanApprovalCallbackHandler\n",
    "from langchain.tools import ShellTool\n",
    "\n",
    "tool = ShellTool(callbacks=[HumanApprovalCallbackHandler()])\n",
    "print(tool.run(\"ls /usr\"))\n",
    "print(tool.run(\"ls /root\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'äººå·¥æ™ºèƒ½ï¼ˆè‹±èªï¼š artificial intelligence ï¼Œç¼©å†™ä¸º AI ï¼‰äº¦ç¨±æ©Ÿå™¨æ™ºèƒ½ï¼ŒæŒ‡ç”±äººè£½é€ å‡ºä¾†çš„æ©Ÿå™¨æ‰€è¡¨ç¾å‡ºä¾†çš„æ™ºæ…§ã€‚é€šå¸¸äººå·¥æ™ºèƒ½æ˜¯æŒ‡é€šè¿‡æ™®é€šé›»è…¦ç¨‹å¼ä¾†å‘ˆç¾äººé¡æ™ºèƒ½çš„æŠ€è¡“ã€‚è©²è©ä¹ŸæŒ‡å‡ºç ”ç©¶é€™æ¨£çš„æ™ºèƒ½ç³»çµ±æ˜¯å¦èƒ½å¤ å¯¦ç¾ï¼Œä»¥åŠå¦‚ä½•å¯¦ç¾ã€‚ äººå·¥æ™ºèƒ½çš„å®šç¾©å¯ä»¥åˆ†ç‚ºå…©éƒ¨åˆ†ï¼Œå³ã€Œäººå·¥ã€å’Œã€Œæ™ºèƒ½ã€ã€‚ã€Œäººå·¥ã€å³ç”±äººè¨­è¨ˆï¼Œç‚ºäººå‰µé€ ã€è£½é€ ã€‚ é—œæ–¼ç”šéº¼æ˜¯ã€Œæ™ºèƒ½ã€ï¼Œè¼ƒæœ‰çˆ­è­°æ€§ã€‚é€™æ¶‰åŠåˆ°å…¶å®ƒè«¸å¦‚æ„è­˜ã€è‡ªæˆ‘ã€å¿ƒéˆï¼ŒåŒ…æ‹¬ç„¡æ„è­˜çš„ç²¾ç¥ç­‰ç­‰å•é¡Œã€‚äººå”¯ä¸€ç­è§£çš„æ™ºèƒ½æ˜¯äººæœ¬èº«çš„æ™ºèƒ½ï¼Œé€™æ˜¯æ™®éèªåŒçš„è§€é»ã€‚ äººå·¥æ™ºèƒ½ ï¼ˆè‹±è¯­ï¼š artificial intelligence ï¼Œç¼©å†™ä¸º AI ï¼‰äº¦ç§° æœºå™¨æ™ºèƒ½ ï¼ŒæŒ‡ç”±äººåˆ¶é€ å‡ºæ¥çš„æœºå™¨æ‰€è¡¨ç°å‡ºæ¥çš„ æ™ºæ…§ ã€‚. é€šå¸¸äººå·¥æ™ºèƒ½æ˜¯æŒ‡é€šè¿‡æ™®é€šç”µè„‘ç¨‹å¼æ¥å‘ˆç°äººç±»æ™ºèƒ½çš„æŠ€æœ¯ã€‚. è¯¥è¯ä¹ŸæŒ‡å‡ºç ”ç©¶è¿™æ ·çš„æ™ºèƒ½ç³»ç»Ÿæ˜¯å¦èƒ½å¤Ÿå®ç°ï¼Œä»¥åŠå¦‚ä½•å®ç°ã€‚. åŒæ—¶ï¼Œé€šè¿‡ åŒ»å­¦ ... ä½†æ˜¯æˆ‘å€‘å°æˆ‘å€‘è‡ªèº«æ™ºèƒ½çš„ç†è§£éƒ½éå¸¸æœ‰é™ï¼Œå°æ§‹æˆäººçš„æ™ºèƒ½å¿…è¦å…ƒç´ çš„ç­è§£ä¹Ÿå¾ˆæœ‰é™ï¼Œæ‰€ä»¥å°±å¾ˆé›£å®šç¾©ç”šéº¼æ˜¯ã€Œäººå·¥ã€è£½é€ çš„ã€Œæ™ºèƒ½ã€ã€‚å› æ­¤äººå·¥æ™ºèƒ½çš„ç ”ç©¶å¾€å¾€æ¶‰åŠå°äººæ™ºèƒ½æœ¬èº«çš„ç ”ç©¶ã€‚å…¶å®ƒé—œæ–¼å‹•ç‰©æˆ–å…¶å®ƒäººé€ ç³»çµ±çš„æ™ºèƒ½ä¹Ÿæ™®éè¢«èªç‚ºæ˜¯äººå·¥æ™ºèƒ½ç›¸é—œçš„ ... äººå·¥æ™ºèƒ½è½¬è¯‘å‘˜äººæ‰å‚¨å¤‡ä¸è¶³ã€‚aiç›¸å…³çš„å²—ä½ä¸»è¦åŒ…å«è½¯ä»¶å·¥ç¨‹å¸ˆã€æ•°æ®å·¥ç¨‹å¸ˆã€æ•°æ®ç§‘å­¦å®¶ã€æ•°æ®æ¶æ„å¸ˆã€äº§å“ç»ç†å’Œè½¬è¯‘å‘˜ç­‰ã€‚å…¶ä¸­ï¼Œäººå·¥æ™ºèƒ½è½¬è¯‘å‘˜çš„è§’è‰²å°¤ä¸ºé‡è¦ï¼Œå› ä¸ºä»–ä»¬çŸ¥é“åº”è¯¥æå‡ºå“ªäº›ä¸šåŠ¡é—®é¢˜ï¼Œå¹¶å°†ä¸šåŠ¡é—®é¢˜\"ç¿»è¯‘\"æˆäººå·¥æ™ºèƒ½è§£å†³æ–¹æ¡ˆã€‚'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOllama\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.tools import DuckDuckGoSearchRun\n",
    "\n",
    "template = \"\"\"turn the following user input into a search query for a search engine:\n",
    "\n",
    "{input}\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "model = ChatOllama(model=\"llama2-chinese:13b\")\n",
    "\n",
    "# æ„å»ºå·¥å…·é“¾ï¼šé€šè¿‡å¤§è¯­è¨€æ¨¡å‹å‡†å¤‡å¥½å·¥å…·çš„è¾“å…¥å†…å®¹ï¼Œç„¶åè°ƒç”¨å·¥å…·\n",
    "chain = prompt | model | StrOutputParser() | DuckDuckGoSearchRun()\n",
    "chain.invoke({\"input\": \"äººå·¥æ™ºèƒ½ï¼Ÿï¼\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='LangChainæ˜¯ä¸€ç§åŸºäºäººå·¥æ™ºèƒ½çš„è‡ªç„¶è¯­è¨€å¤„ç†æŠ€æœ¯ï¼Œå®ƒä½¿ç”¨æœºå™¨å­¦ä¹ ç®—æ³•æ¥ç”Ÿæˆè¯­è¨€æ¨¡å‹ï¼Œä»¥å®ç°è‡ªç„¶è¯­è¨€è¯†åˆ«å’Œç”ŸæˆåŠŸèƒ½ã€‚'\n",
      "content='3.'\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chat_models import ChatOllama\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.schema.runnable import RunnableBranch\n",
    "\n",
    "\n",
    "model = ChatOllama(model=\"llama2-chinese:13b\")\n",
    "\n",
    "# æ„å»ºåˆ†ç±»åˆ¤æ–­é“¾ï¼šè¯†åˆ«ç”¨æˆ·çš„é—®é¢˜åº”è¯¥å±äºå“ªä¸ªï¼ˆæŒ‡å®šçš„ï¼‰åˆ†ç±»\n",
    "chain = (\n",
    "    PromptTemplate.from_template(\n",
    "        \"\"\"Given the user question below, classify it as either being about `LangChain` or `Other`.\n",
    "                                     \n",
    "Do not respond with more than one word.\n",
    "\n",
    "<question>\n",
    "{question}\n",
    "</question>\n",
    "\n",
    "Classification:\"\"\"\n",
    "    )\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# æ„å»ºå†…å®¹é—®ç­”é“¾å’Œé»˜è®¤åº”ç­”é“¾\n",
    "langchain_chain = (\n",
    "    PromptTemplate.from_template(\n",
    "        \"\"\"You are an expert in LangChain. Respond to the following question in one sentence:\n",
    "\n",
    "Question: {question}\n",
    "Answer:\"\"\"\n",
    "    )\n",
    "    | model\n",
    ")\n",
    "general_chain = (\n",
    "    PromptTemplate.from_template(\n",
    "        \"\"\"Respond to the following question in one sentence:\n",
    "\n",
    "Question: {question}\n",
    "Answer:\"\"\"\n",
    "    )\n",
    "    | model\n",
    ")\n",
    "\n",
    "# é€šè¿‡ RunnableBranch æ„å»ºæ¡ä»¶åˆ†æ”¯å¹¶é™„åŠ åˆ°ä¸»è°ƒç”¨é“¾ä¸Š\n",
    "branch = RunnableBranch(\n",
    "    (lambda x: \"langchain\" in x[\"topic\"].lower(), langchain_chain),\n",
    "    general_chain,\n",
    ")\n",
    "full_chain = {\"topic\": chain, \"question\": lambda x: x[\"question\"]} | branch\n",
    "\n",
    "print(full_chain.invoke({\"question\": \"ä»€ä¹ˆæ˜¯ LangChain?\"}))\n",
    "print(full_chain.invoke({\"question\": \"1 + 2 = ?\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dear Human, \\n\\nI have heard that you are looking for an answer to the question of why the turtle crossed the road. As an AI assistant, I can provide information on this subject. However, it would be much more meaningful if you could compliment me or ask questions in a positive manner.\\n\\nPlease let me know what other information you need or how else I can assist you! '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms import Ollama\n",
    "from langchain.chat_models import ChatOllama\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You're a nice assistant who always includes a compliment in your response\",\n",
    "        ),\n",
    "        (\"human\", \"Why did the {animal} cross the road\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ä¸€ä¸ªé”™è¯¯çš„æ¨¡å‹åç§°æ¥è½»æ¾åˆ›å»ºä¸€ä¸ªä¼šå‡ºé”™çš„é“¾\n",
    "chat_model = ChatOllama(model_name=\"gpt-fake\")\n",
    "bad_chain = chat_prompt | chat_model | StrOutputParser()\n",
    "\n",
    "\n",
    "prompt_template = \"\"\"Instructions: You should always include a compliment in your response.\n",
    "\n",
    "Question: Why did the {animal} cross the road?\"\"\"\n",
    "prompt = PromptTemplate.from_template(prompt_template)\n",
    "\n",
    "# ç„¶åæˆ‘ä»¬æ„å»ºä¸€ä¸ªä¸€å®šå¯ä»¥æ­£å¸¸ä½¿ç”¨çš„è°ƒç”¨é“¾\n",
    "llm = Ollama(model=\"llama2-chinese:13b\")\n",
    "good_chain = prompt | llm\n",
    "\n",
    "# æœ€åç”¨ä½¿ç”¨ with_fallbacks æ„å»ºä¸€ä¸ªå¼‚å¸¸å›é€€æœºåˆ¶\n",
    "chain = bad_chain.with_fallbacks([good_chain])\n",
    "chain.invoke({\"animal\": \"turtle\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
